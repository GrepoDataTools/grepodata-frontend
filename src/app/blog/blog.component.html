<div style="width: 100%; min-width: 100%; background: #fff">

  <div class="container-fluid">
    <div class="row">
      <div class="hidden-xs hidden-sm hidden-md col-lg-3 text-left">
        <div class="affix contents">
          <h4 (click)="scroll(Introduction)">Introduction</h4>
          <h4 (click)="scroll(Overview)">Overview</h4>
          <h4 (click)="scroll(Clients)">Client Services</h4>
            <h5 (click)="scroll(Frontend)">Angular Frontend</h5>
              <h6 (click)="scroll(AuthFront)">Authentication</h6>
            <h5 (click)="scroll(Discord)">Discord Bot</h5>
            <h5 (click)="scroll(Userscript)">Userscript</h5>
              <h6 (click)="scroll(Authenticate)">Authentication</h6>
            <h5 (click)="scroll(api)">Indexer API</h5>
          <h4 (click)="scroll(Data)">Data Processing</h4>
            <h5 (click)="scroll(GameData)">Grepolis Game Data</h5>
            <h5 (click)="scroll(InternalData)">Internal Data</h5>
          <h4 (click)="scroll(Databases)">Databases</h4>
            <h5 (click)="scroll(MySQL)">MySQL</h5>
            <h5 (click)="scroll(Elasticsearch)">Elasticsearch</h5>
            <h5 (click)="scroll(Redis)">Redis</h5>
        </div>
      </div>
      <div class="col-md-12 col-lg-8 text-center">
        <br/>
        <h1>Blog: GrepoData Architecture</h1><br/>
        <h6 class="gd-primary">September 2021 by Camiel Kerkhofs</h6>

        <h4 #Introduction style="text-align: left;">Introduction</h4>
        <h5 align="justify">Since the new indexer version went live in April, we received some questions about how our website works, specifically in regards to authentication.
          For the sake of transparency and to answer these questions we wrote this blogpost to discuss some of the architecture choices we made.
          In terms of compute, we are currently running all of this on a single VM with 4 vCPU's and 8 GB RAM.
        </h5>

        <br/>
        <h4 #Overview style="text-align: left">Architecture Overview</h4>
        <h5 align="justify">
          Below is an overview of the complete GrepoData architecture. We have 3 client services. The in-game userscript and the Angular frontend both communicate with our PHP backend. The Discord bot requires a dedicated bot service that runs 24/7.
          We use a MySQL database for our relational data, an Elasticsearch node to enable our search functionality and a Redis in-memory cache to reduce database load for heavy queries.
          In the rest of this blog we will explain how we use each of these tools to deliver GrepoData to our 20.000 unique monthly users.
        </h5>

        <div class="">
          <img style="max-width: 100%; margin: auto;" src="assets/images/architecture.png">
        </div>

        <h4 #Clients style="text-align: left">Client Services</h4>
        <h5 align="justify">

        </h5>


        <br/>
        <h5 #Frontend class="subtitle" style="text-align: left">Angular Frontend</h5>
        <h5 align="justify">
          The frontend being served at https://grepodata.com is an Angular 11 application. Angular provides us with a modular architecture, two-way data binding, dependency injection, improved performance, and cross-platform development capabilities.
          There are still some big items that we would like to add to our Angular app such as internationalisation and lazy loading to improve the speed of our application but unfortunately that would require a rewrite of a large part of the frontend code.
        </h5>
        <h6 #AuthFront class="subtitle" style="text-align: left">Authentication</h6>
        <h5 align="justify">
          The GrepoData indexer tool is protected by a user sign in. Anybody is free to create an account. We use a JSON Web Tokens (JWT) for authentication. JWT is an open standard (RFC 7519) that defines a compact and self-contained way for securely transmitting information between parties as a JSON object. This information can be verified and trusted because it is digitally signed.
          Our JWTs are signed by the GrepoData backend using a secret. All sensitive user data such as the password is stored using industry best practices. We never store such data as plain text.
        </h5>
        <br/>
        <h5 #Discord class="subtitle" style="text-align: left">Discord Bot</h5>
        <h5 align="justify">
          The Discord bot is a bot service that users can add to their Discord servers. We wrote the bot using the popular discord.js library. Currently our bot is serving in 3000 Discord servers with a total of over 50.000 users.
          This is challenge because if your bot is in more than 2500 servers, the server side client needs to be sharded.
          We are currently using the discord.js <a href="https://discordjs.guide/sharding/#how-does-sharding-work" target="_blank">ShardingManager</a> to run multiple shards on the same machine.
          A list of available commands can be found here: <a href="https://grepodata.com/discord" target="_blank">grepodata.com/discord</a>.
        </h5>

        <br/>
        <h5 #Userscript class="subtitle" style="text-align: left">In-Game Userscript <a class="source-link" href="https://github.com/GrepoDataTools/grepodata-backend/tree/master/Software/Application/Indexer" target="_blank">(View Source)</a></h5>
        <h5 align="justify">
          The userscript itself is only used as an injection trigger. Whenever the user loads the game, the userscript will be triggered due to the matching url (*.grepolis.com). The only task of the Userscript is then to inject a .js and .css file that contain the code to run the in-game functionality of our City Indexer tool.
          The injected .js script enables the following functions:
          <ul>
            <li><strong>Authentication:</strong> Get a JWT token to authenticate all subsequent requests.</li>
            <li><strong>Indexing Reports:</strong> Users can click on 'Index +' to submit the entire report HTML to our backend via a POST request.</li>
            <li><strong>Browsing Intel:</strong> Users can browse town intel and notes for each town by doing a GET request to our backend.</li>
            <li><strong>Adding Notes:</strong> Notes can be added via a POST request to the backend.</li>
            <li><strong>Forum Reactions:</strong> Users can react to forum posts and see the reactions of teammates.</li>
          </ul>
        </h5>

        <br/>
        <h6 #Authenticate class="subtitle" style="text-align: left">Userscript Authentication Flow</h6>
        <h5 align="justify">

          Once the userscript is started, it attempts to get a JWT access token from our backend using the refresh token in local storage. If we are unable to get a valid access token, the authentication flow is triggered by calling <a href="https://github.com/GrepoDataTools/grepodata-backend/blob/651e00fd3efdcfb5e178f203de21a7c0e49dad58/Software/Application/Indexer/indexer.js#L1000" target="_blank">showLoginPopup()</a>:
          <ul>
            <li><strong>(1):</strong> First we get a <i>script_token</i> from our backend. This token is linked to the current client.</li>
            <li><strong>(2):</strong> The login popup is displayed, showing a link with the <i>script_token</i> in the payload. The user clicks on this link and the frontend opens in a new tab.</li>
            <li><strong>(3):</strong> Once the link has been clicked by the user, we start calling checkScriptToken() at a 5 second interval. </li>
            <li><strong>(4):</strong> Meanwhile, the user has been redirected to our frontend. Here we check if the user is already logged in to get an <i>access_token</i>. </li>
            <li><strong>(5):</strong> If the user is not logged in, we show a login screen and get an <i>access_token</i> by calling our backend with the given credentials. </li>
            <li><strong>(6):</strong> Now that we have both an <i>access_token</i> and a <i>script_token</i>, we POST them to the backend. This lets the backend know that the <i>script_token</i> has been authenticated by this specific user (identified by the <i>access_token</i>). </li>
            <li><strong>(7):</strong> checkScriptToken() sends the <i>script_token</i> to the backend to check if it has already been verified. </li>
            <li><strong>(8):</strong> The backend returns an <i>access_token</i> and a <i>refresh_token</i> for the user that authenticated the <i>script_token</i> in step 6. These JWT tokens are used to authenticate all subsequent requests. </li>
          </ul>
        </h5>

        <div class="">
          <img style="max-width: 100%; margin: auto;" src="assets/images/architecture_auth.png">
        </div>

        <br/>
        <br/>

        <h5 #api class="subtitle" style="text-align: left">GrepoData Indexer API</h5>
        <h5 align="justify">
          The public GrepoData API provides programmatic access to intel collected by the authenticated user. We also provide authentication endpoints.
          Advanced users can retrieve intel for towns, players or alliances. Our authentication service ensures that users can only retrieve intel that was collected by themselces or their teammates.
          <br/>The API documentation is available here (account required): <a href="https://grepodata.com/profile/api" target="_blank">grepodata.com/profile/api</a>
        </h5>
        <br/>

        <h4 #Data style="text-align: left">Scheduled Data Processing</h4>
        <h5 align="justify">
          In total, we use 20 data processing jobs written in PHP. Each job is on a custom cron schedule. We differentiate between jobs that sync game data and jobs that clean/process our internal data.
        </h5>
        <br/>
        <h5 #GameData class="subtitle" style="text-align: left">Grepolis Game Data</h5>
        <h5 align="justify">
          For each game server, there are 11 files of game data to be collected. Some files are pulled every hour while others are only pulled once per day.
          Game data is made available as compressed csv files. Unfortunately, these files are only updated once every 1 or 2 hours, and by the time they are released they are already out of date. This means that we can never show real-time game data, but we try to get as close as possible.
          <ul>
            <li>[server].grepolis.com/data/<strong>players.txt.gz</strong></li>
            <li>[server].grepolis.com/data/<strong>alliances.txt.gz</strong></li>
            <li>[server].grepolis.com/data/<strong>towns.txt.gz</strong></li>
            <li>[server].grepolis.com/data/<strong>islands.txt.gz</strong></li>
            <li>[server].grepolis.com/data/<strong>player_kills_all.txt.gz</strong></li>
            <li>[server].grepolis.com/data/<strong>player_kills_att.txt.gz</strong></li>
            <li>[server].grepolis.com/data/<strong>player_kills_def.txt.gz</strong></li>
            <li>[server].grepolis.com/data/<strong>alliance_kills_all.txt.gz</strong></li>
            <li>[server].grepolis.com/data/<strong>alliance_kills_att.txt.gz</strong></li>
            <li>[server].grepolis.com/data/<strong>alliance_kills_def.txt.gz</strong></li>
            <li>[server].grepolis.com/data/<strong>conquers.txt.gz</strong></li>
          </ul>
        </h5>
        <br/>
        <h5 #InternalData class="subtitle" style="text-align: left">Internal Data</h5>
        <h5 align="justify">
          We also require some data processing jobs to synchronize and clean our databases or to preprocess data. To this end, we have jobs to aggregate indexer data, index data to Elasticsearch, reset daily score trackers, generate aggregated usage statistics, detect new game servers, cleanup indexer data, cleanup stopped game servers, cleanup old diffs in Elasticsearch, build world maps, enhance indexer data and cleanup remaining data.
          Below is an overview of the CRON schedule of all of these jobs.
        </h5>


        <div class="">
          <img style="max-width: 100%; margin: auto;" src="assets/images/cron.png">
        </div>

        <br/>
        <br/>
        <h4 #Databases style="text-align: left">Databases</h4>
        <h5 #MySQL class="subtitle" style="text-align: left">MySQL</h5>
        <h5 align="justify">
          MySQL is used to store most of our data. Due to the large amount of lookup queries, we make sure to add indexes wherever required. In order to limit the number of inserts, we only update/create records if their values have changed. This also allows our scheduled data processing jobs to be much more efficient. To achieve this, we simply keep a local copy of the game data in csv format. When new data is pulled, we first compare it against the previous data dump, and only persist records to the database if there has been a change.
        </h5>
        <br/>
        <h5 #Elasticsearch class="subtitle" style="text-align: left">Elasticsearch</h5>
        <h5 align="justify">
          Elasticsearch is a search engine based on Lucene. GrepoData uses Elasticsearch to index player and alliance names. This allows us to query half a million names within milliseconds. We use the fuzzy matching algorithm to return results even when the user makes a spelling mistake. The aggregation feature also comes in handy to allow the user to filter based on country and server. A custom scoring function was created to promote results that are on the same game server as the user.
          <br/>We also use our Elasticsearch node to host the attack & defend diffs. Whenever a player gains an attack or defend point, we store this event as a 'diff'. We use the powerful aggregation features of Elasticsearch to quickly aggregate millions of diffs to render the diffs shown on our daily scoreboard.
        </h5>
        <br/>
        <h5 #Redis class="subtitle" style="text-align: left">Redis</h5>
        <h5 align="justify">
          Redis is an in-memory key-value store. We monitor our SQL database for heavy queries and if their functionality allows for cached responses then we will use Redis to store the results of a query for a limited time.
          Mostly we use this approach for requests related to our city indexer where we have some larger queries that aggregate user intel. For example, we cache the alliance and player intelligence pages for 5 minutes. Changes to the underlying data are infrequent and of little consequence while these queries may sometimes take 5 to 10 seconds if the user has collected a lot of intelligence.
          In addition to being used as a cache, we also use Redis to implement our rate limiter. The PHP backend tracks rate limited resources using Redis. If the rate limit is exceeded, our service can respond appropriately.
        </h5>
        <br/>


        <br/>
        <br/>
        <br/>

        <h5 align="justify">
          Our source code is available on GitHub: <a href="https://github.com/grepodatatools" target="_blank">github.com/grepodatatools</a>
        </h5>

        <br/>
      </div>


    </div>
  </div>

</div>
